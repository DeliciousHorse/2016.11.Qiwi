Solution
========

Task was easy, but that's not what I wanted to share

So there was this +300M brainfuck file... (329 080 541 to be precise).

It was a multilayer, so every next layer was also brainfuck file but a lot smaller:

    329 080 541 original
     41 145 939 file1
      5 148 580 file2
        646 203 file3
         82 092 file4
         10 991 file5
          1 914 file6
            221 file7
            
last file was following python script:

```python
import hashlib
class Tolkien:
    def __init__(self):
        self.quote = 'Not all those who wander are lost'
if __name__ == '__main__':
    t = Tolkien()
    print(hashlib.md5(t.quote.encode('utf-8')).hexdigest())
```

(If solution is the only thing that you're interested in, you can stop reading here)

----

AOT v1
======

So the biggest problem was probably making interpreter that is able to crunch that 300M file.

But without much hassle, I got an interpreter that could do that in **30s.**

That was certainly fine for CTF, but it bothered me for some time and I thought that's lame, so I've come up with an idea
of making an AOT for this task. I have bad experiances with asmjit, and I was already familiar with luajit's dynasm
(http://github.com/gim913/dynasm-jit-playground), so I thought about using it.

I came up with following code (boilerplate dynasm code removed) [first.cpp](first.cpp)

That's where the problems started. Internally dynasm is handling some sort of sections and it's getting problematic, if you'll
have to many labels (and that certainly will be the case for a brainfuck to x64 binary translation).

The problem comes from the fact how it's calculating so called 'positions' into pointers within a sections.
I've tried requesting some help on luajit mailing list, but without much luck.

I was to lazy to analyze the code and do a proper fix, so instead I've changed the macros that handle calculations, so I've turned following
macros from `dynasm_x86.h`:

```
/* Macros to convert positions (8 bit section + 24 bit index). */

#define DASM_POS2IDX(pos)       ((pos)&0x00ffffff)
#define DASM_POS2BIAS(pos)      ((pos)&0xff000000)
#define DASM_SEC2POS(sec)       ((sec)<<24)
#define DASM_POS2SEC(pos)       ((pos)>>24)
#define DASM_POS2PTR(D, pos)    (D->sections[DASM_POS2SEC(pos)].rbuf + (pos))
```

into (I know I have only one section, so we'll use only single bit for section, and 31 bits for index):
```cpp
#define DASM_POS2IDX(pos)       ((pos)&0x7fffffff)
#define DASM_POS2BIAS(pos)      ((pos)&0x80000000)
#define DASM_SEC2POS(sec)       ((sec)<<31)
#define DASM_POS2SEC(pos)       ((pos)>>31)
#define DASM_POS2PTR(D, pos)    (D->sections[DASM_POS2SEC(pos)].rbuf + pos)
```

Now that itself did not work, as the input file was big enough to cause integer calculations, so I've fixed few more things:

```cpp
typedef struct dasm_Section {
  int *rbuf;		/* Biased buffer pointer (negative section bias). */
  int *buf;		/* True buffer pointer. */
  size_t bsize;		/* Buffer size in bytes. */
  size_t /*int*/ pos;		/* Biased buffer position. */
  size_t /*int*/ epos;		/* End of biased buffer position - max single put. */
  int ofs;		/* Byte offset into section. */
} dasm_Section;
```

pos and epos in struct above became `size_t`, and at beginnig of `dasm_put`, there was also `pos` that became `size_t`
`size_t pos = sec->pos;`

now there's one more thing that might be a problem if you don't have 4G of free mem ^^
basically dasm rellocation always try to double memory, I didn't need that, but you might need following hack,
that slows down allocation a bit once you hit 512M:

```cpp
#ifndef DASM_M_GROW
#define DASM_M_GROW(ctx, t, p, sz, need) \
  do { \
    size_t _sz = (sz), _need = (need); \
    if (_sz < _need) { \
      if (_sz < 16) _sz = 16; \
      if (_sz < 1024 * 1024 * 1024) \
          while (_sz < _need) _sz += _sz; \
      else \
          while (_sz < _need) _sz += 128 * 1024 * 1024; \
      (p) = (t *)realloc((p), _sz); \
      if ((p) == NULL) exit(1); \
      (sz) = _sz; \
    } \
  } while(0)
#endif
```

So with all of that in place it finally worked, and I was able to get get output of 300M file in time between **16-26 secs**
(depending on avail memory, allocations, system load etc.)

I've tried playing a bit with dynasm allocator (not to reallocate section), but that did not give much boost.

I collected bit more details, about time taken (in seconds):

| action          | time          |
| --------------- | -------------:|
| code generation |          5.19 |
|     dynasm link |          1.73 |
|     encode time |          3.25 | 
|  execution time |          5.22 |
| --------------- | ------------- |
| overall         |         15.39 |

At this point I thought, I should be able to beat 3 first parts, as dynasm needs to take care about handling labels.

But brainfuck is simple, so I thought it shouldn't be that hard to beat that value, right?


AOT v2
======

And it isn't :)

We can generate all the code on the fly in a single pass.

But first reminder how brainfuck loops work like.

 * `[` - if `byte(data pointer) == 0`, jump after `]`
 * `]` - jump back to correpsonding opening `[`

So we will need simple trick when generating [, we'll gonna make following code:

```asm
loop_start:
  cmp [rdi], 0
  jnz continue_loop
  jmp dummy_value
continue_loop:

  ... code goes here

; now handle closing brace
jmp loop_start
loop_end:
```

When generating, I'm gonna track all loop starts on the stack, and when generating
jump at closing brace:
 * get from the stack position of `loop_start`, and generate `jmp loop_start`
 * calculate proper value to fill `dummy_value`, so that the jump will go to `loop_end`

That is what [second.cpp](second.cpp) does, easy peasy, time **6.53** :)

| action          | time          |
| --------------- | -------------:|
| code generation |          1.25 |
|  execution time |          5.28 |
| --------------- | ------------- |
| overall         |          6.53 |


Optimize
========

Now, next question is, can this get any better? Sure, with just a little bit of cheating.

The key is an observation, that there are many loops in the file that look like:
`[---->++<]`

I'm storing this as a new insturction that will have arguments `M(count1, count2)`
count1 is negative if there were `-` and positive it it were `+`, but in the
files provided count1 is always negative.

The preprocessing step is bit lengthy, but it's not that complicated and it looks as follows

```cpp
enum State {
	Find_Loop,
	Store_Sym,
	Check_Sym,
	Check_Loop_End
};

void optimize(uint8_t* program, size_t programSize) {
	size_t start = 0;
	size_t locGpc = start;

	State state = Find_Loop;
	size_t loopStartGpc = 0;
	int symId = 0;
	int sym[2];
	int symCount[2];

	while (locGpc < programSize)
	{
		switch (state) {
		case Find_Loop:
			if ('[' == program[locGpc]) {
				loopStartGpc = locGpc;
				symId = 0;
				sym[0] = 0;
				state = Store_Sym;
			}
			locGpc++;
			break;
		case Store_Sym:
			if ('+' == program[locGpc] || '-' == program[locGpc]) {
				sym[symId] = program[locGpc];
				symCount[symId] = 1;
				state = Check_Sym;
				locGpc++;
			} else {
				state = Find_Loop;
			}
			break;
		case Check_Sym:
			if (sym[symId] == program[locGpc]) {
				++symCount[symId];
				locGpc++;
			} else if ('>' == program[locGpc] && 0 == symId) {
				symId = 1;
				sym[1] = 0;
				state = Store_Sym;
				locGpc++;
			} else if ('<' == program[locGpc] && 1 == symId) {
				state = Check_Loop_End;
				locGpc++;
			} else {
				state = Find_Loop;
			}
			break;
		case Check_Loop_End:
			if (']' == program[locGpc]) {
				if (symCount[0] > 10 || symCount[1] > 10) {
					fprintf(stderr, "too big values in optimizable loop\n");
					exit(0);
				}
				program[loopStartGpc++] = 'M';
				program[loopStartGpc++] = (sym[0] == '-') ? -symCount[0] : symCount[0];
				program[loopStartGpc++] = (sym[1] == '-') ? -symCount[1] : symCount[1];
				locGpc++;

				for (; loopStartGpc < locGpc; ++loopStartGpc)
					program[loopStartGpc] = ' ';

			}
			state = Find_Loop;
			break;
		}
	}
}
```

So I'm changing whole loop into `M(a,b)` filling the rest with blanks.
This can be used to calculate value of next cell as follows (pseudo code):
```
M(a,b)
	starting = cell[ current ]
	a = -a
	while (starting % a)
		starting += 256;

	result = starting / a * b;
	cell[ current ] = 0
	cell[ current + 1 ] += result;
```

How to use it is along with [second.cpp](second.cpp) is left as an excercise.

Now time for the final number **time: 2.8s** :)

Summary
=======

Obviously last step is a cheat, and if applied directly
to interpreter, it would improve it's speed as well.

 - Is it an overkill? Who am I to argue.
 - Was it fun? OFC

Point was, that even from dumb task, you can get somewhat valuable knowledge.

